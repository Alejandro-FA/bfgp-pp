//
// Created by js on 24/05/22.
//

#ifndef __SEARCH_BEST_FIRST_SEARCH_H__
#define __SEARCH_BEST_FIRST_SEARCH_H__

#include <stop_token>
#include <mutex>
#include <atomic>
#include <syncstream>
#include "frontiers/frontier.h"
#include "engine.h"
#include "../generalized_planning_problem.h"

namespace search {
    class BFS : public Engine {
    public:
        explicit BFS(std::unique_ptr<theory::Theory> theory, std::unique_ptr<GeneralizedPlanningProblem> gpp,
                     std::unique_ptr<Frontier> open = std::make_unique<Frontier>(), std::size_t id = 0) // By default, uses the unprotected Frontier
            : Engine{std::move(theory), std::move(gpp)}, _best_evaluations(_evaluation_functions.size(), INF),
            _open{std::move(open)}, _id{id} {
            //_bitvec_theory = false;
        }

        /// Stop source used to interrupt the search when another thread has found a solution.
        /// If the new stop source is shared by multiple BFS instances, it can be used to interrupt them.
        void set_stop_source(std::stop_source ssource) {
            _stop_source = std::move(ssource);
        }

        /// Sets a limit to the _open queue size. If this limit is reached, the search will stop.
        /// Useful to create a particular amount of work to be distributed.
        void set_open_size_limit(std::size_t limit) {
            _queue_size_limit = limit;
        }

        void remove_open_size_limit() {
            _queue_size_limit = std::numeric_limits<std::size_t>::max();
        }

        [[nodiscard]] bool is_empty() const {
            return _open->empty();
        }

        /// NOTE: This method can be called from different threads, so it must be thread-safe.
        void add_node(std::shared_ptr<Node> node, bool convert=false) {
            node->get_program()->clear_program_states(); // Before adding the node, clear up the program states to save memory
            if (convert) node = node->copy_to(_gpp.get()); // If the node has been generated by another GPP, make a copy tied to this GPP
            node->set_id(_next_node_id++); // Assign a consistent id regardless of where does this node come from
            _open->push(std::move(node));
        }

        std::shared_ptr<Node> select_node() {
            return _open->select_node();
        }

        [[nodiscard]] bool is_goal(Node* node, bool run_program, bool only_active_instances) {
            auto p {node->get_program()};
            auto vps {run_program ? p->run(_gpp.get(), false, only_active_instances) : p->get_program_states()};
            _last_failed_instance_idx = -1;

            // FIXME: if this happens, then progressive mode fails
            if (vps.empty()) {
                //std::cout <<run_program << "\n"<< p->to_string(false) << std::endl;
                _last_failed_instance_idx = p->get_failed_instance_idx();
                return false; // Check whether some error occurred during execution
            }

            id_type local_id = 0;
            for(const auto& idx : _gpp->get_instance_idxs(only_active_instances)){
            //for (id_type id = 0; id < (id_type)vps.size(); id++) {
            //    if(_gpp->is_progressive() and (not _gpp->is_instance_active(id))) continue;
                auto ins = _gpp->get_instance(idx);
                auto line = vps[local_id]->get_line();
                auto end = dynamic_cast<const instructions::End*>(p->get_instruction(line));
                // It is not a goal, if the instruction is not an END
                if(end == nullptr) {
                    _last_failed_instance_idx = idx;
                    return false;
                }
                // If the instruction is an END, it cannot be a goal if it is not applicable
                //if(not end->is_applicable(ins, vps[local_id].get())) {  /// vps is a vector of unique pointers
                if(not end->is_applicable(ins, vps[local_id])) {  /// vps is a vector of raw pointers
                    _last_failed_instance_idx = idx;
                    return false;
                }
                // Special test for theory 'actions'
                if(_gpp->is_actions_theory()){
                    // Close world assumption: goal is a state, so check that all what is true in the state holds
                    auto goal_state = ins->get_goal_state();
                    for(const auto& fact : vps[local_id]->get_state()->get_facts()){
                        auto f_name = fact->get_name();
                        if(f_name.size() > 8u and f_name.substr(0,8) == "(action_") continue;
                        if(fact->get_value() != goal_state->get_value(fact)) {
                            _last_failed_instance_idx = idx;
                            return false;
                        }
                    }
                }

                ++local_id;
            }
            return true;
        }

        [[nodiscard]] std::vector<std::shared_ptr<Node> > expand_node(Node* node) {
            //int pc_max = -1;
            auto p = node->get_program();
            auto instructions = p->get_instructions();
            int pc_max = p->get_pc_max();  /// Retrieve pc_max from previous program execution

            // Failure case either when the next valid line is not found or if an instruction is already programmed
            if (pc_max == -1 or p->get_instruction(pc_max) != nullptr) return {};

            //bool only_end = false;  // ToDo: implement after bitvec theory
            //if(_bitvec_theory and pc_max > 0){
            //    auto ins_str = p->get_instruction(pc_max-1)->to_string(false);
            //    if(ins_str.find("vector(ptr-goal) =") != std::string::npos)
            //        only_end = true;
            //}

            std::vector<std::shared_ptr<Node> > childs;
            auto gd = _gpp->get_generalized_domain();
            int maxi = std::max(1, int(_evaluation_functions.size()));

            for (const auto &ins: gd->get_instructions()) {
//std::cout << "[INFO] checking new expansion with instruction:\n" << ins->to_string(true) << "\n";
                /******
                //if(_bitvec_theory){  // ToDo: implement after bitvec theory
                //    auto ins_end = std::dynamic_pointer_cast<instructions::End>(i);
                //    if(only_end and not ins_end) continue;
                //}
                 // Check if the instruction is an ITE
                //auto ins_ite = dynamic_cast<instructions::bitvec::ITE*>(ins);  // ToDo: implement after bitvec theory
                //if(ins_ite){ // ToDo: implement after bitvec theory
                //    // 1. Check first if only ite can be programmed
                //    if (not only_branching) continue;
                //}
                 *****/

                if(nullptr != base_program and (not check_base_constraints(p, pc_max, ins))) continue;

                if( not _theory->check_syntax_constraints(p, pc_max, ins) or
                    not _theory->check_semantic_constraints(_gpp.get(), p, pc_max, ins)) continue;

                // Make a new child
                auto p2 = p->copy();
                p2->set_instruction(pc_max, ins);

                // Special expansion for CPP theory.
                // If the current instruction is a FOR, we also program an ENDFOR at destination line
                auto ins_for = dynamic_cast<const instructions::For*>(ins);
                if (ins_for) {
                    auto for_ptr = ins_for->get_pointer();
                    auto dest_line = ins_for->get_destination_line();
                    auto endfor_name = "endfor(" + for_ptr->get_name() + (ins_for->get_modifier()>0?"++":"--") +
                            "," + std::to_string(pc_max) + ")";
                    auto endfor_instruction = gd->get_instruction(endfor_name);
                    p2->set_instruction(dest_line, endfor_instruction);
                }

                // Update constraints
                //_theory->update(p2.get(), ins);

                childs.emplace_back(std::make_shared<Node>(std::move(p2), vec_value_t(maxi, 0)));
            }
            _expanded_nodes++;
            return childs;
        }

        [[nodiscard]] std::shared_ptr<Node> solve(std::vector<std::unique_ptr<Program>> roots = {}) override {
            if(roots.empty()){
                /// Initialize the empty root program
                roots.emplace_back(std::make_unique<Program>(_gpp.get())); // Caution! Assumes that Program constructor does not read nor write active instances
                this->base_program = nullptr;
            }
            else{
                /// Otherwise, constraints are added from the input program (last in roots) to avoid search duplicates
                this->base_program = roots[roots.size()-1]->copy();
                /// Also check whether the base program is a goal
                std::scoped_lock lock{_pgp_mutex}; // Ensures that during evaluation no new instances are activated
                _theory->set_initial_program(_gpp.get(), this->base_program.get());
                auto base_node = std::make_shared<Node>(this->base_program->copy(),
                                                        vec_value_t(_evaluation_functions.size(), INF));
                // if the program solves all instances finish
                bool all_goal = is_goal(base_node.get(), true, false);
                if (all_goal) {
                    base_node->set_f(f(base_node.get()));
                    add_node(base_node);
                    _stop_source.request_stop();
                    return base_node;
                }
            }

            if (_open->empty()) { // Only add nodes if the queue is empty (otherwise we could repeat work of other threads)
                for(int idx = roots.size()-1; idx >= 0; idx--){
    //std::cout << "[INFO] new root node " << std::endl << roots[idx]->to_string(true) << std::endl;
                    std::scoped_lock lock{_pgp_mutex}; // Ensures that during evaluation no new instances are activated
                    _theory->set_initial_program(_gpp.get(), roots[idx].get());
                    roots[idx]->run(_gpp.get()); /// This must be the first and unique run of each root
                    auto root_node =std::make_shared<Node>(std::move(roots[idx]),
                                                           vec_value_t(_evaluation_functions.size(), INF));
                    root_node->set_f(f(root_node.get()));
                    add_node(std::move(root_node));
                }
            }

            while (!_open->empty() and !_stop_source.stop_requested() and _open->size() < _queue_size_limit) {
                auto current {_open->select_node()};
                auto children {expand_node(current.get())};
//std::cout << "[INFO] Selecting node:\n" << current->to_string() << "\n";
                _current_evaluations = current->f();
//std::cout << "[INFO] Total new expansions = " << children.size() << "\n";
                if (_current_evaluations < _best_evaluations) {
                    _best_evaluations = _current_evaluations;
                    print_node(current.get());
                }
                else if (_verbose and _expanded_nodes % PROGRAM_FREQUENCY == 0) {
                    print_node(current.get());
                }

                for (const auto &child: children) {
                    if (_stop_source.stop_requested()) break;

//std::cout << "[INFO] New child to evaluate:\n" << child->to_string() << "\n";
                    /// Checked in the expansion
                    //vps = child->get_program()->run( _gpp.get() );
                    //if (vps.empty()) continue;
                    /*if( _bitvec_theory ) { // closed list of visited program states
                        std::vector<vec_value_t> vvs;
                        for (const auto &ps: vps) vvs.emplace_back(ps->as_vector());
                        if (_closed_program_states.find(vvs) != _closed_program_states.end()) continue;
                        _closed_program_states.insert(vvs);
                    }*/

                    // Evaluate the child (this must be the first and unique run of the program)
                    // Issue #4: keep the program run right before node evaluation, since PGP could change
                    // the number of active instances, hence yield to an inconsistent evaluation
                    bool activate_instance {false};

                    { // The lock of this section prevents other threads from activating instances, but allows them read access
                        std::scoped_lock lock{_pgp_mutex};

                        auto vps {child->get_program()->run(_gpp.get())};
                        if(vps.empty()) continue;
                        child->set_f(f(child.get()));

                        if (is_goal(child.get(), false, true)) {
                            if (_verbose) std::osyncstream{std::cout} << "[INFO] Solution candidate!\n" << child->to_string();
                            // if the program solves all instances finish
                            bool all_goal = is_goal(child.get(), true, false);
                            if (all_goal) {
                                child->set_f(f(child.get()));
                                add_node_request(child);
                                _stop_source.request_stop();
                                return child;
                            }
                            else{
                                // Get the failure id
                                assert(_last_failed_instance_idx != -1);
                                assert(not _gpp->is_instance_active(_last_failed_instance_idx));
                                activate_instance = true; // Indicate that the failed instance must be activated
                                add_node_request(child); // add the current child, just in case is a correct partial solution
                            }
                        }
                        else {
                            // Standard A* but no chance to repeat programs so nodes are always pushed into priority queue
                            add_node_request(child);
                        }
                    }

                    if (activate_instance) {
                        if (_verbose)
                            std::osyncstream{std::cout}
                                << "[ENGINE " << _id << "] Failure on instance "
                                << _last_failed_instance_idx + 1 << ", reevaluating...\n";
                        activate_instance_request(_last_failed_instance_idx);
                    }
                }
            }

            return nullptr;
        }

        /// NOTE: This method can be called from different threads, so it must be thread-safe.
        void activate_and_reevaluate(id_type instance_idx) {
            std::scoped_lock lock{_pgp_mutex}; // Unique access to the GPP active instances. No other thread can read nor write the active instances.
            if (_gpp->is_instance_active(instance_idx)) return; // There is a small chance that 2 threads simultaneously request the activation of the same instance
            _gpp->activate_instance(instance_idx);
            value_t next_id {_next_node_id.load()};
            _open->reevaluate([this](const Node* node) { return f(node); }, _gpp.get(), next_id);
            _next_node_id.exchange(next_id);
            if (_verbose) std::osyncstream{std::cout} << "[ENGINE " << _id << "] Reevaluation done!\n";
        }

        [[nodiscard]] vec_value_t current_evaluations() const {
            return _current_evaluations;
        }

        [[nodiscard]] vec_value_t best_evaluations() const {
            return _best_evaluations;
        }

    protected:
        /// Requests to add a new node to the search queue. Parallel algorithms can override this method to distribute
        /// nodes.
        virtual void add_node_request(std::shared_ptr<Node> node) {
            add_node(std::move(node));
        }

        /// Requests to activate an instance (and reevaluate the queue accordingly). Parallel algorithms can override
        /// this method to synchronize the activation.
        virtual void activate_instance_request(id_type instance_idx) {
            activate_and_reevaluate(instance_idx);
        }

    private:
        // accumulated cost
        //virtual value_t g(const Node* node) = 0;

        // heuristic functions
        //virtual vec_value_t h(const Node* node) = 0;

        [[nodiscard]] vec_value_t f(const Node* node) {
            _evaluated_nodes++;
            auto p = node->get_program();
            vec_value_t val_h;
            val_h.reserve(_evaluation_functions.size());
            for (const auto &ef: _evaluation_functions)
                val_h.emplace_back(ef->compute(p, _gpp.get()));
            return val_h;
        }

        [[nodiscard]] bool check_base_constraints(const Program *p, size_t pc_max, const instructions::Instruction* ins) const{
            /// Validates if exists a line with non-empty instructions where 'p' and 'base_program' programs differ
            /// Input:
            ///  - 'p', the Program to validate
            ///  - 'pc_max', which is the current line to program in 'p'
            ///  - 'ins', the instruction to program at 'pc_max'
            /// Returns:
            ///  - true, if one non-empty instruction differs
            ///  - false, otherwise
            if(nullptr == base_program->get_instruction(pc_max)) return true;
            if(ins->get_id() != base_program->get_instruction(pc_max)->get_id()) return true;
            for(size_t line = 0; line < p->get_num_instructions(); line++){
                auto base_ins = base_program->get_instruction(line);
                auto p_ins = p->get_instruction(line);
                if(nullptr == base_ins or nullptr == p_ins) continue;
                if(base_ins->get_id() != p_ins->get_id()) return true;
            }
            return false;
        }

        void print_node(Node *n) const {
            if (not _verbose) return;
            std::osyncstream oss{std::cout};
            oss << "[ENGINE " << _id << "]\n";
            oss << "Node id=" << n->get_id() << "\n";
            oss << "Expanded=" << _expanded_nodes << "\n";
            {
                std::scoped_lock lock{_pgp_mutex};
                oss << "Evaluated=" << _evaluated_nodes << "\n";
            }
            oss << "Open queue size=" << _open->size() << "\n";
            oss << n->to_string() << "\n";
        }

    private:
        std::atomic<id_type> _next_node_id {0};

        // Search constraints
        std::size_t _queue_size_limit{std::numeric_limits<std::size_t>::max()};
        std::unique_ptr<Program> base_program;

        // TEST
        id_type _last_failed_instance_idx{-1};
        vec_value_t _best_evaluations; // Keep value between solve calls
        vec_value_t _current_evaluations;
        //bool _bitvec_theory;
        //std::set<std::vector<vec_value_t>> _closed_program_states;

        mutable std::mutex _pgp_mutex; // Mutex to protect the active instances of a GPP from being modified while a node is being evaluated and added to the queue

    protected:
        std::unique_ptr<Frontier> _open;
        std::size_t _id {0}; // Unique identifier for the engine
        std::stop_source _stop_source; // Used to request the search to stop when a solution is found.
    };
}

#endif //__SEARCH_BEST_FIRST_SEARCH_H__
